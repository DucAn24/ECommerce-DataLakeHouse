filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /var/log/sample/*.log
    - /var/log/*.log
  exclude_files: ['\.gz$']
  fields:
    logtype: application
    environment: dev
  fields_under_root: false
  multiline.pattern: '^\d{4}-\d{2}-\d{2}'
  multiline.negate: true
  multiline.match: after

- type: container
  enabled: true
  paths:
    - /var/lib/docker/containers/*/*.log
  processors:
    - add_docker_metadata:
        host: "unix:///var/run/docker.sock"

# Kafka Output for Real-time Processing
output.kafka:
  enabled: true
  hosts: ["kafka:29092"]
  topic: "filebeat-logs"
  partition.round_robin:
    reachable_only: false
  required_acks: 1
  compression: gzip
  max_message_bytes: 1000000

# Also output to Elasticsearch for immediate search
output.elasticsearch:
  enabled: false  # Disable direct ES output, use Kafka -> Flink -> ES pipeline
  hosts: ["elasticsearch:9200"]
  index: "filebeat-logs-%{+yyyy.MM.dd}"

# Logging
logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0644

# Processors
processors:
  - add_host_metadata:
      when.not.contains.tags: forwarded
  - add_cloud_metadata: ~
  - add_docker_metadata: ~
  - add_kubernetes_metadata: ~
  - timestamp:
      field: '@timestamp'
      layouts:
        - '2006-01-02T15:04:05.000Z'
        - '2006-01-02T15:04:05.000-07:00'
      test:
        - '2019-06-22T16:33:51.000Z'
        - '2019-11-18T04:59:51.123Z'

# Template settings
setup.template.settings:
  index.number_of_shards: 1
  index.codec: best_compression

# ILM Policy
setup.ilm.enabled: auto
setup.ilm.rollover_alias: "filebeat"
setup.ilm.pattern: "{now/d}-000001"

# Kibana dashboard
setup.dashboards.enabled: true
setup.kibana:
  host: "kibana:5601"

# Monitoring
monitoring.enabled: true
